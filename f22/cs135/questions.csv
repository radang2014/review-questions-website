Id,Question,Type,Preformatted,Image,Option 1,Image 1,Option 2,Image 2,Option 3,Image 3,Option 4,Image 4,Option 5,Image 5,Option 6,Image 6,Option 7,Image 7,Option 8,Image 8,Option 9,Image 9,Option 10,Image 10,Option 11,Image 11,Option 12,Image 12,Option 13,Image 13,Option 14,Image 14,Option 15,Image 15,Correct Answer
1,Which of the following is true regarding the relationship between Artificial Intelligence and Machine Learning?,MC,,,Artificial Intelligence is a subfield of Machine Learning.,,Machine Learning is a subfield of Artificial Intelligence.,,Artificial Intelligence and Machine Learning are equivalent fields.,,Artificial Intelligence and Machine Learning are completely unrelated from each other.,,,,,,,,,,,,,,,,,,,,,,,,2
2,"When using gradient descent to update weights, the change in weight is...",MC,,,in the same direction as the loss gradient.,,in the opposite direction as the loss gradient.,,in the same direction as the loss gradient if the loss gradient is positive and in the opposite direction if the loss gradient is negative,,in the same direction as the loss gradient if the loss gradient is negative and in the opposite direction if the loss gradient is positive.,,,,,,,,,,,,,,,,,,,,,,,,4
3,"Suppose that you are using polynomial regression to solve a supervised learning problem. As the degree of the polynomial increases, the training error will...",MC,,,increase.,,decrease.,,increase then decrease.,,decrease then increase.,,,,,,,,,,,,,,,,,,,,,,,,2
4,"When completing a certain round of 20-fold cross-validation, what proportion of the data is used to train the model?",MC,,,5%,,20%,,80%,,95%,,,,,,,,,,,,,,,,,,,,,,,,4
5,All of the following are classifiers EXCEPT...,MC,,,Ridge Regression,,Logistic Regression,,Multi-Layer Perceptron,,Decision Trees,,,,,,,,,,,,,,,,,,,,,,,,1
6,"When compared to One-Versus-One classification, in One-Versus-All Classification, meeting the requirements for linear separability is _____, and _____ classifiers are necessary.",MC,,,"easier, fewer",,"easier, more",,"harder, fewer",,"harder, more",,,,,,,,,,,,,,,,,,,,,,,,3
7,"Consider the following statistics:
<table><tr><td>True Positives</td><td>10</td></tr><tr><td>True Negatives</td><td>15</td></tr><tr><td>False Positives</td><td>20</td></tr><tr><td>False Negatives</td><td>30</td></tr></table>
What is the true positive rate?",MC,,,25%,,33.33%,,40%,,50%,,,,,,,,,,,,,,,,,,,,,,,,1
8,"Suppose that in your training data set, you had the following three data points (format: \([x_1, x_2]\)): \([0, 100]\), \([5, 50]\), and \([10, 0]\), and you wanted to use feature standardization for feature engineering. What would be the data points after feature standardization?
<i>The feature standard deviations are: \([\sigma_1, \sigma_2] = [5, 50]\)</i>",MC,,,"\([0, 1]\), \([0.5, 0.5]\), and \([1, 0]\)",,"\([0, 1]\), \([0.05, 0.5]\), and \([0.1, 0]\)",,"\([-1, 1]\), \([0, 0]\), and \([1, -1]\)",,"\([0, 2]\), \([1, 1]\), and \([2, 0]\)",,,,,,,,,,,,,,,,,,,,,,,,3
9,"The ""kernel trick"" can allow for the learning of a separator for data that is not linearly separable. How?",MC,,,New features are added that are linear combinations of existing features.,,New features are added that are non-linear combinations of existing features.,,A kernel function transforms the data into a space where the points are linearly separable.,,The ability to learn weights across multiple hidden layers allows for a non-linear separator.,,,,,,,,,,,,,,,,,,,,,,,,3
10,"In a Feed-Forward neural network, which of the following processes can be parallelized?",MC,,,Learning the weights of different neurons within the same layer,,Learning the weights of different neurons in different layers that are connected to each other,,All of the above,,None of the above,,,,,,,,,,,,,,,,,,,,,,,,1
11,"Suppose that you have a 4-sided die that is rigged so that it lands on 1 50% of the time, lands on 2 25% of the time, and lands on 3 and 4 12.5% of the time each. What is the number of bits of information yielded while rolling the die?
<i>This is the Shannon Entropy with a log base of 2.</i>",MC,,,0.875,,1.75,,2,,2.25,,,,,,,,,,,,,,,,,,,,,,,,2
12,Reinforcement learning problems are...,MC,,,regression supervised learning problems.,,classification supervised learning problems.,,semi-supervised learning problems.,,unsupervised learning problems.,,,,,,,,,,,,,,,,,,,,,,,,3
13,"In a Markov decision process, if the time horizon (\(T\)) is infinite, we should make sure that the discount rate (\(\gamma\)) is...",MC,,,positive.,,negative.,,less than 1.,,greater than 1.,,,,,,,,,,,,,,,,,,,,,,,,3
14,"For a K Nearest Neighbors classifier, looking at a large number of neighbors is likely to result in...",MC,,,an underfit model.,,an appropriately fit model.,,an overfit model.,,Number of neighbors has no effect on underfitting/overfitting.,,,,,,,,,,,,,,,,,,,,,,,,1
15,"The use of inverse document frequency in a ""Bag of Words"" document model seeks to emphasize...",MC,,,words found a few times in the average document over words found many times in the average document.,,words found many times in the average document over words found a few times in the average document.,,words found in a few documents over words found in many documents.,,words found in many documents over words found in a few documents.,,,,,,,,,,,,,,,,,,,,,,,,3
